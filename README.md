
## Animal Behavior Anomaly Detection via Spatio-Temporal Puzzle pre-train | AROB 2025 Experimental Repository |2025 AROB å®Ÿé¨“ãƒªãƒã‚¸ãƒˆãƒª 

### ğŸ¾ğŸ¾ğŸ¾Overview  
This project focuses on the task of **anomaly detection in animal behavior videos** using the [Animal Kingdom dataset](https://sutdcv.github.io/Animal-Kingdom/).  <br>
For self-supervised pretraining, we adopt [Space-Time Jigsaw Puzzles](https://arxiv.org/pdf/1811.09795) and use it in [VAD](https://link.springer.com/chapter/10.1007/978-3-031-20080-9_29).  <br>
The following models are supported:  
- [TimeSFormer](https://arxiv.org/pdf/2102.05095)  
- [SwinTransformer](https://arxiv.org/abs/2106.13230)  
- [C3D](https://arxiv.org/pdf/1412.0767)  
- [R3D](https://arxiv.org/pdf/1711.11248v3)
- 
### ğŸ¾ğŸ¾ğŸ¾æ¦‚è¦
å‹•ç‰©è¡Œå‹•å‹•ç”»[Animal Kingdomãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://sutdcv.github.io/Animal-Kingdom/)ã‚’å¯¾è±¡ã¨ã—ãŸç•°å¸¸è¡Œå‹•æ¤œå‡ºã‚¿ã‚¹ã‚¯ã§ã™ã€‚<br>
äº‹å‰å­¦ç¿’ã¨ã—ã¦[Space-Time Cubic Puzzles](https://arxiv.org/pdf/1811.09795)ãŠä½¿ã„ã€[VAD](https://link.springer.com/chapter/10.1007/978-3-031-20080-9_29)ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚<br>
å¯¾å¿œã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ä¸‹è¨˜ã®é€šã‚Šã€‚
- [TimeSFormer](https://arxiv.org/pdf/2102.05095)
- [SwinTransformer](https://arxiv.org/abs/2106.13230)
- [C3D](https://arxiv.org/pdf/1412.0767)
- [R3D](https://arxiv.org/pdf/1711.11248v3)

### ğŸš€ğŸš€ğŸš€Setup  
Please follow the steps below to set up the environment before running the project.

1. To set up the environment directly using Conda:  <br>
    Run the following commands in sequence:
    ```
    conda create -n animal-VAD python=3.10 -y
    conda activate animal-VAD
    pip install --upgrade pip
    pip install -r requirements.txt
    conda install tensorboard
    pip install numpy==1.26.4 # Reinstall numpy because tensorboard may upgrade it
    ```

2. To set up the environment using Docker:  <br>
    Follow these steps:  <br>
    1. Build an image from the Dockerfile:
        ```
        docker build . -t img_env-ViViT
        ```
    2. Create a container from the image:
        ```
        docker run -v ./:/work -n env-ViViT -it img_env-ViViT
        ```

### ğŸš€ğŸš€ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
å®Ÿè¡Œã™ã‚‹å‰ã«ä¸‹è¨˜æ‰‹é †ã‚’å‚è€ƒã«ã—ã¦ç’°å¢ƒæ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚
1. Condaã§ç›´æ¥ç’°å¢ƒæ§‹ç¯‰ã™ã‚‹å ´åˆ<br>
    ä¸‹è¨˜ã‚³ãƒãƒ³ãƒ‰ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ç’°å¢ƒæ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚
    ```
    conda create -n env-ViViT python=3.10 -y
    conda activate env-ViViT
    pip install --upgrade pip
    pip install -r requirements.txt
    conda install tensorboard
    pip install numpy==1.26.4 # tensorboardã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨numpyãŒã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã•ã‚Œã‚‹ãŸã‚å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    ```
2. Dockerã§ç’°å¢ƒæ§‹ç¯‰ã™ã‚‹å ´åˆ<br>
    ä¸‹è¨˜æ‰‹é †ã§ç’°å¢ƒæ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚<br>
    1. Dockerfileã‹ã‚‰ã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰
        ```
        docker build . -t img_env-ViViT
        ```
    2. ã‚¤ãƒ¡ãƒ¼ã‚¸ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ
        ```
        docker run -v ./:/work -n env-ViViT -it img_env-ViViT
        ```
        
### ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ How to Use  
After setting up the environment, you can start training with the following command. Hyperparameters are specified in `config.yml`.  <br>
```
python main.py -config_path config.yml
```
In `config.yml`, specify the <u>model type</u>, <u>dataset type</u>, and training parameters:  
```
pretrain:
    is_valid    : False     # Enable/disable pretraining
    epoch       : 15        # Pretraining epochs
    batch_size  : 8         
    num_workers : 4
    optimizer   : adamw     
    lr          : 0.0005    
    weight_decay: 0.05      

train:
    epoch       : 30        # Training epochs
    batch_size  : 8         
    num_workers : 4
    optimizer   : adamw     
    lr          : 0.0005    
    weight_decay: 0.05      

dataset:
    type: K400-S-Separate   # Dataset type

model:
    type: TimeSFormer       # Model type

others:
    rnd_seed      : 1
    running_path  : ./logs
    result_path   : ./results
```

- Experiment Shell Script  <br>
  If you want to run multiple experiments, save each config in the `configs` folder and execute `run.sh`.  <br>
  The script will run `main.py` for each `.yml` file in the folder automatically.  
```
./run.sh
```

- Model Type  <br>
Model types are defined in `model/model_zoo.yml`:  
```
# Example: VideoSwinTransformer base model definition
Swin-B:
    Architecture: SwinTransformer3D
    patch_size: (4,4,4)
    embed_dim: 128
    depths: [2, 2, 18, 2]
    num_heads: [4,8,16,32]
    window_size: (8,7,7)
    mlp_ratio: 4.
    qkv_bias: True
    qk_scale: None
    drop_rate: 0.
    attn_drop_rate: 0.
    drop_path_rate: 0.2
    patch_norm: True

    cls_head:
        in_channels: 1024
```

- Dataset Type  <br>
Dataset types are defined in `dataset/dataset_zoo.yml`. The `pretrain_type` is defined in `dataset/pretrain_scheme/pretrain_zoo.yml`.  
```
â˜†â˜†â˜† dataset_zoo.yml â˜†â˜†â˜†
# Example: KineticsK400 dataset definition
K400-S-Separate:
    datatype          : KineticsK400
    num_classes       : 400
    n_sample_per_class: 0.3   # Use 30% of data per class for classification

    img_size          : 224
    n_frames          : 16
    frame_interval    : 2
    
    train_path        : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_train
    valid_path        : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_valid
    movie_ext         : .mp4

    train_transforms: 
        scale       : None
        ratio       : None
        hflip       : 0.5
        color_jitter: 0.4
        norm_mean   : (0.485, 0.456, 0.406)
        norm_std    : (0.229, 0.224, 0.225)

    valid_transforms: 
        norm_mean   : (0.485, 0.456, 0.406)
        norm_std    : (0.229, 0.224, 0.225)

    pretrain:
        pretrain_type     : SeparateJigsawPuzzle3D
        pretrain_path     : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_train
        n_sample_per_class: 1.0
```

```
â˜†â˜†â˜† pretrain_zoo.yml â˜†â˜†â˜†
# Example: JointJigsawPuzzle3D definition
JointJigsawPuzzle3D:
    type             : JointJigsawPuzzle3D
    n_grid           : (2,2,4)         # Grid split in (h, w, t)
    mask_grid_ratio  : 0.125           # Masking ratio for pretraining
```

- Data Path Configuration  <br>
Specify `train_path`, `valid_path`, and `pretrain_path` in `dataset_zoo.yml`. The dataset folder should follow the structure below:  
```
train_path
â”œâ”€â”€ classmap.json       # JSON mapping of class names to indices
â”‚                       # Example: { "CLASS_A":1, "CLASS_B":2, "CLASS_C":3 }
â”œâ”€â”€ CLASS_A
â”‚   â”œâ”€â”€ 001.mp4
â”‚   â”œâ”€â”€ 002.mp4
â”‚   â””â”€â”€ 003.mp4
â”œâ”€â”€ CLASS_B
â”‚   â”œâ”€â”€ 001.mp4
â”‚   â”œâ”€â”€ 002.mp4
â”‚   â””â”€â”€ 003.mp4
â””â”€â”€ CLASS_C
    â”œâ”€â”€ 001.mp4
    â”œâ”€â”€ 002.mp4
    â””â”€â”€ 003.mp4
```
### ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ ä½¿ã„æ–¹
- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ç’°å¢ƒæ§‹ç¯‰ã—ãŸå¾Œã§ä¸‹è¨˜ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã¾ã™ã€‚å­¦ç¿’ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯config.ymlã§æŒ‡å®šã§ãã¾ã™ã€‚
    ```
    python main.py -config_path config.yml
    ```
    config.ymlã§ã¯ä½¿ç”¨ã™ã‚‹<u>ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—</u>ã¨<u>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—</u>ã€å­¦ç¿’ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã—ã¾ã™ã€‚
    ```
    pretrain:
        is_valid    : False     # äº‹å‰å­¦ç¿’ã®æœ‰ç„¡(Falseã¯ç„¡)
        epoch       : 15        # äº‹å‰å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
        batch_size  : 8         # ãƒãƒƒãƒæ•°
        num_workers : 4
        optimizer   : adamw     # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        lr          : 0.0005    # å­¦ç¿’ç‡
        weight_decay: 0.05      # é‡ã¿æ­£å‰‡åŒ–

    train:
        epoch       : 30        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°
        batch_size  : 8         # ãƒãƒƒãƒæ•°
        num_workers : 4
        optimizer   : adamw     # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        lr          : 0.0005    # å­¦ç¿’ç‡
        weight_decay: 0.05      # é‡ã¿æ­£å‰‡åŒ–

    dataset:
        type: K400-S-Separate #ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã¯ã€ŒK400-S-Separateã€ã‚’ä½¿ç”¨

    model:
        type: TimeSFormer    #ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã¯ã€ŒTimeSFormerã€ã‚’ä½¿ç”¨

    others:
        rnd_seed      : 1
        running_path  : ./logs
        result_path   : ./results
    ```
- å®Ÿé¨“ç”¨ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ<br>
 è¤‡æ•°ã®å®Ÿé¨“è¨­å®šã®ä¸‹ã§æ¯”è¼ƒå®Ÿé¨“ã‚’è¡Œã„ãŸã„å ´åˆã€å®Ÿé¨“è¨­å®šã‚’config.ymlã«è¨˜è¿°ã—ã€é †æ¬¡configsãƒ•ã‚©ãƒ«ãƒ€ã¸æ ¼ç´ã—ã¦ã„ãã€ã€Œrun.shã€ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚<br>
 ã€Œrun.shã€ã¯configsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ymlãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¼•æ•°ã¨ã—ã¦ã€ã€Œmain.pyã€ã‚’é †æ¬¡å®Ÿè¡Œã™ã‚‹ãŸã‚ã€è‡ªå‹•ã§å®Ÿé¨“ãŒé€²ã‚“ã§ã„ãã¾ã™ã€‚
    ```
    ./run.sh
    ```

- ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—<br>
ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã¯ä¸‹è¨˜ã®ã‚ˆã†ã«model/model_zoo.ymlã§å®šç¾©ã—ã¾ã™ã€‚
    ```
    # VideoSwinTransformerã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ä¾‹
    Swin-B:
        Architecture: SwinTransformer3D
        patch_size: (4,4,4)
        embed_dim: 128
        depths: [2, 2, 18, 2]
        num_heads: [4,8,16,32]
        window_size: (8,7,7)
        mlp_ratio: 4.
        qkv_bias: True
        qk_scale: None
        drop_rate: 0.
        attn_drop_rate: 0.
        drop_path_rate: 0.2
        patch_norm: True

        cls_head:
            in_channels: 1024
    ```
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—<br>
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã¯ä¸‹è¨˜ã®ã‚ˆã†ã«dataset/dataset_zoo.ymlã§å®šç¾©ã—ã¾ã™ã€‚ãªãŠã€äº‹å‰å­¦ç¿’ã®ã‚¿ã‚¤ãƒ—ã€Œpretrain_typeã€ã¯dataset/pretrain_scheme/pretrain_zoo.ymlã§å®šç¾©ã—ã¦ãŠãã¾ã™ã€‚
    ```
    â˜†â˜†â˜†ã€€dataset_zoo.ymlã€€â˜†â˜†â˜†
    # KineticsK400ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©ä¾‹
    K400-S-Separate:
        datatype          : KineticsK400
        num_classes       : 400
        n_sample_per_class: 0.3   # ã‚¯ãƒ©ã‚¹åˆ†é¡æ™‚ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¨ä½“ã®30%

        img_size          : 224
        n_frames          : 16
        frame_interval    : 2
        
        train_path        : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_train # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¸ã®ãƒ‘ã‚¹
        valid_path        : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_valid # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¸ã®ãƒ‘ã‚¹
        movie_ext         : .mp4

        train_transforms: 
            scale       : None
            ratio       : None
            hflip       : 0.5
            color_jitter: 0.4
            norm_mean   : (0.485, 0.456, 0.406)
            norm_std    : (0.229, 0.224, 0.225)

        valid_transforms: 
            norm_mean   : (0.485, 0.456, 0.406)
            norm_std    : (0.229, 0.224, 0.225)

          pretrain:
            pretrain_type     : SeparateJigsawPuzzle3D # äº‹å‰å­¦ç¿’ã®ã‚¿ã‚¤ãƒ—ã¯ã€ŒSeparateJigsawPuzzle3Dã€
            pretrain_path     : /mnt/d/Work/Create/RD_REPOS/20240808_Transformerç³»ã®ãƒ¢ãƒ‡ãƒ«ã«3DCubicPuzzleã‚’å¿œç”¨ã™ã‚‹/K400_train
            n_sample_per_class: 1.0 # äº‹å‰å­¦ç¿’æ™‚ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯100%
    ```
    ```
    â˜†â˜†â˜†ã€€pretrain_zoo.ymlã€€â˜†â˜†â˜†
    # JointJigsawPuzzle3Dã®å®šç¾©ä¾‹
    JointJigsawPuzzle3D:
        type          : JointJigsawPuzzle3D # Jigsawã®ã‚¿ã‚¤ãƒ—ã¯ã€ŒJointã€
        n_grid        : (2,2,4) # (h,w,t)ã®æ¬¡å…ƒã§åˆ†å‰²ã™ã‚‹ã‚°ãƒªãƒƒãƒ‰æ•°ã¯(2,2,4)
        mask_grid_ratio: 0.125  # ãƒã‚¹ã‚¯ã™ã‚‹ã‚°ãƒªãƒƒãƒ‰ã®å‰²åˆ
    ```

- ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®ãƒ‘ã‚¹ã¯dataset_zoo.ymlã®train_pathãŠã‚ˆã³valid_pathã€pretrain_pathã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚<br>
  ãªãŠã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€å†…ã®æ§‹é€ ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹é€ ã«ãªã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚<br>
  ```
  train_path
    â”œâ”€â”€ classmap.jsonï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒ©ã‚¹åã¨å¯¾å¿œã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨˜è¿°ã—ãŸjsonãƒ•ã‚¡ã‚¤ãƒ«ã€‚
    |                ã€€ä¸‹è¨˜ã®ä¾‹ã§ã¯{ "CLASS_A":1,"CLASS_B":2,"CLASS_C":3}ã¨ãªã‚‹ã€‚
    â”œâ”€â”€ CLASS_A
    â”‚   â”œâ”€â”€ 001.mp4ï¼šã‚¯ãƒ©ã‚¹Aã«å±ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    â”‚   â”œâ”€â”€ 002.mp4
    â”‚   â””â”€â”€ 003.mp4
    â”œâ”€â”€ CLASS_B
    â”‚   â”œâ”€â”€ 001.mp4ï¼šã‚¯ãƒ©ã‚¹Bã«å±ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    â”‚   â”œâ”€â”€ 002.mp4
    â”‚   â””â”€â”€ 003.mp4
    â””â”€â”€ CLASS_C
        â”œâ”€â”€ 001.mp4ï¼šã‚¯ãƒ©ã‚¹Cã«å±ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        â”œâ”€â”€ 002.mp4
        â””â”€â”€ 003.mp4
  ```
